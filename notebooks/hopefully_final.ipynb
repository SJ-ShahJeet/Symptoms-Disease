{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca07f859-02af-47dd-adf0-8e8da67fa49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246945, 378)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseases</th>\n",
       "      <th>anxiety and nervousness</th>\n",
       "      <th>depression</th>\n",
       "      <th>shortness of breath</th>\n",
       "      <th>depressive or psychotic symptoms</th>\n",
       "      <th>sharp chest pain</th>\n",
       "      <th>dizziness</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>abnormal involuntary movements</th>\n",
       "      <th>chest tightness</th>\n",
       "      <th>...</th>\n",
       "      <th>stuttering or stammering</th>\n",
       "      <th>problems with orgasm</th>\n",
       "      <th>nose deformity</th>\n",
       "      <th>lump over jaw</th>\n",
       "      <th>sore in nose</th>\n",
       "      <th>hip weakness</th>\n",
       "      <th>back swelling</th>\n",
       "      <th>ankle stiffness or tightness</th>\n",
       "      <th>ankle weakness</th>\n",
       "      <th>neck weakness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diseases  anxiety and nervousness  depression  shortness of breath  \\\n",
       "0  panic disorder                        1           0                    1   \n",
       "1  panic disorder                        0           0                    1   \n",
       "2  panic disorder                        1           1                    1   \n",
       "3  panic disorder                        1           0                    0   \n",
       "4  panic disorder                        1           1                    0   \n",
       "\n",
       "   depressive or psychotic symptoms  sharp chest pain  dizziness  insomnia  \\\n",
       "0                                 1                 0          0         0   \n",
       "1                                 1                 0          1         1   \n",
       "2                                 1                 0          1         1   \n",
       "3                                 1                 0          1         1   \n",
       "4                                 0                 0          0         1   \n",
       "\n",
       "   abnormal involuntary movements  chest tightness  ...  \\\n",
       "0                               0                1  ...   \n",
       "1                               0                0  ...   \n",
       "2                               0                0  ...   \n",
       "3                               1                0  ...   \n",
       "4                               1                1  ...   \n",
       "\n",
       "   stuttering or stammering  problems with orgasm  nose deformity  \\\n",
       "0                         0                     0               0   \n",
       "1                         0                     0               0   \n",
       "2                         0                     0               0   \n",
       "3                         0                     0               0   \n",
       "4                         0                     0               0   \n",
       "\n",
       "   lump over jaw  sore in nose  hip weakness  back swelling  \\\n",
       "0              0             0             0              0   \n",
       "1              0             0             0              0   \n",
       "2              0             0             0              0   \n",
       "3              0             0             0              0   \n",
       "4              0             0             0              0   \n",
       "\n",
       "   ankle stiffness or tightness  ankle weakness  neck weakness  \n",
       "0                             0               0              0  \n",
       "1                             0               0              0  \n",
       "2                             0               0              0  \n",
       "3                             0               0              0  \n",
       "4                             0               0              0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")\n",
    "\n",
    "# Preview\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4329bf2-a1d3-4f25-8ae4-471605ed3730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique symptoms: 377\n"
     ]
    }
   ],
   "source": [
    "# Symptoms are all columns except 'diseases'\n",
    "symptom_list = list(df.columns[1:])\n",
    "print(f\"Total unique symptoms: {len(symptom_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff45019-4b97-4380-a5d3-b57e7ad43916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Load pretrained model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create embeddings for each symptom and store in dictionary\n",
    "symptom_embeddings = {\n",
    "    symptom: model.encode(symptom, convert_to_tensor=True) for symptom in symptom_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7408c1-dd3c-47ab-8be1-72b12023347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    filtered = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f74004-1d26-4ac5-9006-350f70662ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_symptoms(user_input, top_k=10):\n",
    "    cleaned = clean_input(user_input)\n",
    "    input_vec = model.encode(cleaned, convert_to_tensor=True)\n",
    "    \n",
    "    matches = [\n",
    "        (symptom, float(util.cos_sim(input_vec, vec)))\n",
    "        for symptom, vec in symptom_embeddings.items()\n",
    "    ]\n",
    "    return sorted(matches, key=lambda x: x[1], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02fe65c-4486-48ca-b6e5-0fe64e34aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_symptom_match(user_input, symptom_list, model, symptom_embeddings, top_k=10):\n",
    "    input_clean = clean_input(user_input)\n",
    "    input_vec = model.encode(input_clean, convert_to_tensor=True)\n",
    "\n",
    "    # Step 1: Semantic matching\n",
    "    semantic_scores = [\n",
    "        (sym, float(util.cos_sim(input_vec, vec)))\n",
    "        for sym, vec in symptom_embeddings.items()\n",
    "    ]\n",
    "    top_semantic = sorted(semantic_scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Step 2: Add exact keyword matches (bonus!)\n",
    "    exact_matches = [sym for sym in symptom_list if sym in input_clean]\n",
    "    for sym in exact_matches:\n",
    "        if sym not in [x[0] for x in top_semantic]:\n",
    "            top_semantic.append((sym, 1.0))  # force-add exact match with high score\n",
    "\n",
    "    return sorted(top_semantic, key=lambda x: x[1], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf80eff-2dc4-43bb-aaf0-7126a40678d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Matches:\n",
      "\n",
      "â†’ fever  (1.0000)\n",
      "â†’ shortness of breath  (0.6854)\n",
      "â†’ sharp chest pain  (0.6162)\n",
      "â†’ burning chest pain  (0.5920)\n",
      "â†’ hurts to breath  (0.5681)\n",
      "â†’ difficulty breathing  (0.5628)\n",
      "â†’ dizziness  (0.5503)\n",
      "â†’ congestion in chest  (0.5317)\n",
      "â†’ abnormal breathing sounds  (0.5028)\n",
      "â†’ irregular heartbeat  (0.4424)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hybrid Matches:\\n\")\n",
    "for symptom, score in hybrid_symptom_match(test_input, symptom_list, model, symptom_embeddings):\n",
    "    print(f\"â†’ {symptom}  ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9f202f4-4bda-40a1-8677-7e7ae8b64760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned input: ive feeling feverish chest pain also bit dizzy lately even cough\n",
      "\n",
      "Hybrid Matches:\n",
      "â†’ cough  (1.0000)\n",
      "â†’ fever  (1.0000)\n",
      "â†’ sharp chest pain  (0.6467)\n",
      "â†’ congestion in chest  (0.5878)\n",
      "â†’ burning chest pain  (0.5795)\n",
      "â†’ dizziness  (0.5706)\n",
      "â†’ shoulder cramps or spasms  (0.5019)\n",
      "â†’ feeling ill  (0.4890)\n",
      "â†’ irregular heartbeat  (0.4673)\n",
      "â†’ feeling hot and cold  (0.4644)\n"
     ]
    }
   ],
   "source": [
    "test_input = \"I've been feeling feverish and my chest pain. Also a bit dizzy lately and even cough.\"\n",
    "\n",
    "print(f\"Cleaned input: {clean_input(test_input)}\\n\")\n",
    "print(\"Hybrid Matches:\")\n",
    "\n",
    "matches = hybrid_symptom_match(test_input, symptom_list, model, symptom_embeddings)\n",
    "\n",
    "for symptom, score in matches:\n",
    "    print(f\"â†’ {symptom}  ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c8ebf29-0958-4519-a813-d1b396ac2a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download once\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Your symptom list (can be expanded)\n",
    "symptom_list = [\n",
    "    \"fever\", \"chest pain\", \"dizziness\", \"headache\", \"shortness of breath\",\n",
    "    \"fatigue\", \"cough\", \"sore throat\", \"nausea\", \"vomiting\"\n",
    "]\n",
    "\n",
    "def clean_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def extract_ngrams(tokens, max_n=3):\n",
    "    all_ngrams = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        ngram_tuples = list(ngrams(tokens, n))\n",
    "        ngram_phrases = [' '.join(gram) for gram in ngram_tuples]\n",
    "        all_ngrams.extend(ngram_phrases)\n",
    "    return all_ngrams\n",
    "\n",
    "def match_ngrams_to_symptoms(user_input, symptom_list):\n",
    "    tokens = clean_input(user_input)\n",
    "    ngram_phrases = extract_ngrams(tokens)\n",
    "    matched = [sym for sym in symptom_list if sym in ngram_phrases]\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4adba327-5bdf-4890-8e48-9a54e2f334a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Symptoms: ['chest pain']\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I feel feverish with some chest pain and I'm dizzy\"\n",
    "matched = match_ngrams_to_symptoms(user_input, symptom_list)\n",
    "print(\"Matched Symptoms:\", matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3ac9b35-2ceb-4374-8bbd-3bf9a2b0112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Imports\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Download stopwords if needed\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# STEP 2: Utility functions\n",
    "def clean_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def extract_ngrams(tokens, max_n=3):\n",
    "    all_ngrams = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        ngram_tuples = list(ngrams(tokens, n))\n",
    "        ngram_phrases = [' '.join(gram) for gram in ngram_tuples]\n",
    "        all_ngrams.extend(ngram_phrases)\n",
    "    return all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16d2e835-2e35-46c3-aef8-5a39552bc627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full symptom list and their embeddings\n",
    "with open(\"../model/model_all_symptoms.pkl\", \"rb\") as f:\n",
    "    symptom_list = pickle.load(f)\n",
    "\n",
    "with open(\"../model/model_symptom_embeddings.pkl\", \"rb\") as f:\n",
    "    symptom_embeddings = pickle.load(f)\n",
    "\n",
    "# Load sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c3026b8-672c-4c54-b0ce-d97d9902ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_symptom_match(user_input, top_k=10):\n",
    "    tokens = clean_input(user_input)\n",
    "    ngram_phrases = extract_ngrams(tokens)\n",
    "\n",
    "    # Step 1: Semantic match\n",
    "    input_vec = model.encode(\" \".join(tokens), convert_to_tensor=True).cpu()\n",
    "    semantic_scores = [\n",
    "        (sym, float(util.cos_sim(input_vec, emb)))\n",
    "        for sym, emb in symptom_embeddings.items()\n",
    "    ]\n",
    "    top_matches = sorted(semantic_scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Step 2: Exact match from n-grams\n",
    "    matched_syms = [sym for sym, _ in top_matches]\n",
    "    for sym in symptom_list:\n",
    "        if sym in ngram_phrases and sym not in matched_syms:\n",
    "            top_matches.append((sym, 0.95))  # Add fallback with high score\n",
    "\n",
    "    return sorted(top_matches, key=lambda x: x[1], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa2d50b9-fee4-424f-a008-146ef320afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ cough (0.9500)\n",
      "â†’ sharp chest pain (0.6292)\n",
      "â†’ burning chest pain (0.6018)\n",
      "â†’ nausea (0.5915)\n",
      "â†’ congestion in chest (0.5680)\n",
      "â†’ vomiting (0.5056)\n",
      "â†’ feeling ill (0.4995)\n",
      "â†’ shoulder cramps or spasms (0.4873)\n",
      "â†’ sore throat (0.4836)\n",
      "â†’ throat redness (0.4811)\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I feel feverish, have chest pain and have cough and even feel like nausea or vomiting\"\n",
    "\n",
    "results = hybrid_symptom_match(user_input)\n",
    "\n",
    "for sym, score in results:\n",
    "    print(f\"â†’ {sym} ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef98b4ff-1e86-42b5-a55f-db7319055b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")\n",
    "\n",
    "# Get list of unique symptoms\n",
    "symptom_list = df.columns[1:].tolist()\n",
    "\n",
    "# Load sentence transformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Precompute symptom embeddings\n",
    "symptom_embeddings = {sym: model.encode(sym, convert_to_tensor=True) for sym in symptom_list}\n",
    "\n",
    "# Clean and tokenize\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Hybrid matcher with n-gram and semantic similarity\n",
    "def extract_symptoms_semantic_phrases(user_input, top_k=10):\n",
    "    tokens = clean_and_tokenize(user_input)\n",
    "    print(tokens)\n",
    "    phrases = []\n",
    "    for n in range(1, 4):\n",
    "        phrases += [\" \".join(gram) for gram in ngrams(tokens, n)]\n",
    "    \n",
    "    seen = set()\n",
    "    scored_matches = []\n",
    "\n",
    "    for phrase in phrases:\n",
    "        if phrase in seen:\n",
    "            continue\n",
    "        seen.add(phrase)\n",
    "\n",
    "        input_vec = model.encode(phrase, convert_to_tensor=True)\n",
    "        scores = [(sym, float(util.cos_sim(input_vec, emb))) for sym, emb in symptom_embeddings.items()]\n",
    "        top_match = max(scores, key=lambda x: x[1])\n",
    "        if top_match[1] > 0.6:\n",
    "            scored_matches.append(top_match)\n",
    "\n",
    "    scored_matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scored_matches[:top_k]\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc57449e-c13b-4373-9dce-64783450bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feel', 'feverish', 'chest', 'pain', 'cough', 'even', 'feel', 'like', 'nausea', 'vomiting', 'even', 'shorten', 'breathing']\n",
      "vomiting â†’ 1.0000\n",
      "cough â†’ 1.0000\n",
      "nausea â†’ 1.0000\n",
      "sharp chest pain â†’ 0.8958\n",
      "nausea â†’ 0.8743\n",
      "fever â†’ 0.8605\n",
      "nausea â†’ 0.8432\n",
      "nausea â†’ 0.8271\n",
      "nausea â†’ 0.8216\n",
      "vomiting â†’ 0.8212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_input = \"I feel feverish, have chest pain and have cough and even feel like nausea or vomiting and even shorten breathing\"\n",
    "results = extract_symptoms_semantic_phrases(test_input)\n",
    "for symptom, score in results:\n",
    "    print(f\"{symptom} â†’ {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bde3e91b-6ef2-4b89-99bd-c6529ec621b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "df = pd.read_csv(\"../data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")\n",
    "symptom_list = df.columns[1:].tolist()\n",
    "\n",
    "# Step 2: Load transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 3: Precompute symptom embeddings\n",
    "symptom_embeddings = {sym: model.encode(sym, convert_to_tensor=True) for sym in symptom_list}\n",
    "\n",
    "# Step 4: Text cleaner\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Step 5: Matching logic with deduplication\n",
    "def extract_symptoms_semantic_phrases(text, top_k=5):\n",
    "    tokens = clean_and_tokenize(text)\n",
    "    \n",
    "    phrases = []\n",
    "    for n in range(1, 4):\n",
    "        phrases += [\" \".join(gram) for gram in ngrams(tokens, n)]\n",
    "\n",
    "    seen = set()\n",
    "    matches = []\n",
    "\n",
    "    for phrase in phrases:\n",
    "        input_vec = model.encode(phrase, convert_to_tensor=True)\n",
    "        scored = [(sym, float(util.cos_sim(input_vec, emb))) for sym, emb in symptom_embeddings.items()]\n",
    "        best_symptom, best_score = max(scored, key=lambda x: x[1])\n",
    "\n",
    "        if best_score > 0.6 and best_symptom not in seen:\n",
    "            seen.add(best_symptom)\n",
    "            matches.append((best_symptom, best_score))\n",
    "\n",
    "    matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    return matches[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9306ca8-5507-41ac-a442-80baf7caa0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ fatigue (0.7206)\n",
      "â†’ insomnia (0.6901)\n",
      "â†’ sleepiness (0.6760)\n",
      "â†’ feeling hot (0.6316)\n"
     ]
    }
   ],
   "source": [
    "test_input = \"I feel tired and unable to sleep\"\n",
    "results = extract_symptoms_semantic_phrases(test_input, top_k=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8367a752-7c2a-412d-9f61-f922c3bd4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Time taken: 2.0046 seconds\n",
      "\n",
      "â†’ fatigue (0.7206)\n",
      "â†’ insomnia (0.6901)\n",
      "â†’ sleepiness (0.6760)\n",
      "â†’ feeling hot (0.6316)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "test_input = \"I feel tired and unable to sleep\"\n",
    "\n",
    "start = time.time()\n",
    "results = extract_symptoms_semantic_phrases(test_input, top_k=10)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\nâœ… Time taken: {end - start:.4f} seconds\\n\")\n",
    "for symptom, score in results:\n",
    "    print(f\"â†’ {symptom} ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62269d2b-fc51-410f-822a-9d8bcf77d867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
