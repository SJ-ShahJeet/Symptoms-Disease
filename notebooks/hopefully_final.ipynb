{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca07f859-02af-47dd-adf0-8e8da67fa49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246945, 378)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseases</th>\n",
       "      <th>anxiety and nervousness</th>\n",
       "      <th>depression</th>\n",
       "      <th>shortness of breath</th>\n",
       "      <th>depressive or psychotic symptoms</th>\n",
       "      <th>sharp chest pain</th>\n",
       "      <th>dizziness</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>abnormal involuntary movements</th>\n",
       "      <th>chest tightness</th>\n",
       "      <th>...</th>\n",
       "      <th>stuttering or stammering</th>\n",
       "      <th>problems with orgasm</th>\n",
       "      <th>nose deformity</th>\n",
       "      <th>lump over jaw</th>\n",
       "      <th>sore in nose</th>\n",
       "      <th>hip weakness</th>\n",
       "      <th>back swelling</th>\n",
       "      <th>ankle stiffness or tightness</th>\n",
       "      <th>ankle weakness</th>\n",
       "      <th>neck weakness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diseases  anxiety and nervousness  depression  shortness of breath  \\\n",
       "0  panic disorder                        1           0                    1   \n",
       "1  panic disorder                        0           0                    1   \n",
       "2  panic disorder                        1           1                    1   \n",
       "3  panic disorder                        1           0                    0   \n",
       "4  panic disorder                        1           1                    0   \n",
       "\n",
       "   depressive or psychotic symptoms  sharp chest pain  dizziness  insomnia  \\\n",
       "0                                 1                 0          0         0   \n",
       "1                                 1                 0          1         1   \n",
       "2                                 1                 0          1         1   \n",
       "3                                 1                 0          1         1   \n",
       "4                                 0                 0          0         1   \n",
       "\n",
       "   abnormal involuntary movements  chest tightness  ...  \\\n",
       "0                               0                1  ...   \n",
       "1                               0                0  ...   \n",
       "2                               0                0  ...   \n",
       "3                               1                0  ...   \n",
       "4                               1                1  ...   \n",
       "\n",
       "   stuttering or stammering  problems with orgasm  nose deformity  \\\n",
       "0                         0                     0               0   \n",
       "1                         0                     0               0   \n",
       "2                         0                     0               0   \n",
       "3                         0                     0               0   \n",
       "4                         0                     0               0   \n",
       "\n",
       "   lump over jaw  sore in nose  hip weakness  back swelling  \\\n",
       "0              0             0             0              0   \n",
       "1              0             0             0              0   \n",
       "2              0             0             0              0   \n",
       "3              0             0             0              0   \n",
       "4              0             0             0              0   \n",
       "\n",
       "   ankle stiffness or tightness  ankle weakness  neck weakness  \n",
       "0                             0               0              0  \n",
       "1                             0               0              0  \n",
       "2                             0               0              0  \n",
       "3                             0               0              0  \n",
       "4                             0               0              0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")\n",
    "\n",
    "# Preview\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4329bf2-a1d3-4f25-8ae4-471605ed3730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique symptoms: 377\n"
     ]
    }
   ],
   "source": [
    "# Symptoms are all columns except 'diseases'\n",
    "symptom_list = list(df.columns[1:])\n",
    "print(f\"Total unique symptoms: {len(symptom_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff45019-4b97-4380-a5d3-b57e7ad43916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Load pretrained model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create embeddings for each symptom and store in dictionary\n",
    "symptom_embeddings = {\n",
    "    symptom: model.encode(symptom, convert_to_tensor=True) for symptom in symptom_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7408c1-dd3c-47ab-8be1-72b12023347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    filtered = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f74004-1d26-4ac5-9006-350f70662ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_symptoms(user_input, top_k=10):\n",
    "    cleaned = clean_input(user_input)\n",
    "    input_vec = model.encode(cleaned, convert_to_tensor=True)\n",
    "    \n",
    "    matches = [\n",
    "        (symptom, float(util.cos_sim(input_vec, vec)))\n",
    "        for symptom, vec in symptom_embeddings.items()\n",
    "    ]\n",
    "    return sorted(matches, key=lambda x: x[1], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02fe65c-4486-48ca-b6e5-0fe64e34aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_symptom_match(user_input, symptom_list, model, symptom_embeddings, top_k=10):\n",
    "    input_clean = clean_input(user_input)\n",
    "    input_vec = model.encode(input_clean, convert_to_tensor=True)\n",
    "\n",
    "    # Step 1: Semantic matching\n",
    "    semantic_scores = [\n",
    "        (sym, float(util.cos_sim(input_vec, vec)))\n",
    "        for sym, vec in symptom_embeddings.items()\n",
    "    ]\n",
    "    top_semantic = sorted(semantic_scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Step 2: Add exact keyword matches (bonus!)\n",
    "    exact_matches = [sym for sym in symptom_list if sym in input_clean]\n",
    "    for sym in exact_matches:\n",
    "        if sym not in [x[0] for x in top_semantic]:\n",
    "            top_semantic.append((sym, 1.0))  # force-add exact match with high score\n",
    "\n",
    "    return sorted(top_semantic, key=lambda x: x[1], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf80eff-2dc4-43bb-aaf0-7126a40678d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Matches:\n",
      "\n",
      "→ fever  (1.0000)\n",
      "→ shortness of breath  (0.6854)\n",
      "→ sharp chest pain  (0.6162)\n",
      "→ burning chest pain  (0.5920)\n",
      "→ hurts to breath  (0.5681)\n",
      "→ difficulty breathing  (0.5628)\n",
      "→ dizziness  (0.5503)\n",
      "→ congestion in chest  (0.5317)\n",
      "→ abnormal breathing sounds  (0.5028)\n",
      "→ irregular heartbeat  (0.4424)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hybrid Matches:\\n\")\n",
    "for symptom, score in hybrid_symptom_match(test_input, symptom_list, model, symptom_embeddings):\n",
    "    print(f\"→ {symptom}  ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9f202f4-4bda-40a1-8677-7e7ae8b64760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned input: ive feeling feverish chest pain also bit dizzy lately even cough\n",
      "\n",
      "Hybrid Matches:\n",
      "→ cough  (1.0000)\n",
      "→ fever  (1.0000)\n",
      "→ sharp chest pain  (0.6467)\n",
      "→ congestion in chest  (0.5878)\n",
      "→ burning chest pain  (0.5795)\n",
      "→ dizziness  (0.5706)\n",
      "→ shoulder cramps or spasms  (0.5019)\n",
      "→ feeling ill  (0.4890)\n",
      "→ irregular heartbeat  (0.4673)\n",
      "→ feeling hot and cold  (0.4644)\n"
     ]
    }
   ],
   "source": [
    "test_input = \"I've been feeling feverish and my chest pain. Also a bit dizzy lately and even cough.\"\n",
    "\n",
    "print(f\"Cleaned input: {clean_input(test_input)}\\n\")\n",
    "print(\"Hybrid Matches:\")\n",
    "\n",
    "matches = hybrid_symptom_match(test_input, symptom_list, model, symptom_embeddings)\n",
    "\n",
    "for symptom, score in matches:\n",
    "    print(f\"→ {symptom}  ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c8ebf29-0958-4519-a813-d1b396ac2a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download once\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Your symptom list (can be expanded)\n",
    "symptom_list = [\n",
    "    \"fever\", \"chest pain\", \"dizziness\", \"headache\", \"shortness of breath\",\n",
    "    \"fatigue\", \"cough\", \"sore throat\", \"nausea\", \"vomiting\"\n",
    "]\n",
    "\n",
    "def clean_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def extract_ngrams(tokens, max_n=3):\n",
    "    all_ngrams = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        ngram_tuples = list(ngrams(tokens, n))\n",
    "        ngram_phrases = [' '.join(gram) for gram in ngram_tuples]\n",
    "        all_ngrams.extend(ngram_phrases)\n",
    "    return all_ngrams\n",
    "\n",
    "def match_ngrams_to_symptoms(user_input, symptom_list):\n",
    "    tokens = clean_input(user_input)\n",
    "    ngram_phrases = extract_ngrams(tokens)\n",
    "    matched = [sym for sym in symptom_list if sym in ngram_phrases]\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4adba327-5bdf-4890-8e48-9a54e2f334a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Symptoms: ['chest pain']\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I feel feverish with some chest pain and I'm dizzy\"\n",
    "matched = match_ngrams_to_symptoms(user_input, symptom_list)\n",
    "print(\"Matched Symptoms:\", matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3ac9b35-2ceb-4374-8bbd-3bf9a2b0112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Imports\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Download stopwords if needed\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# STEP 2: Utility functions\n",
    "def clean_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def extract_ngrams(tokens, max_n=3):\n",
    "    all_ngrams = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        ngram_tuples = list(ngrams(tokens, n))\n",
    "        ngram_phrases = [' '.join(gram) for gram in ngram_tuples]\n",
    "        all_ngrams.extend(ngram_phrases)\n",
    "    return all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16d2e835-2e35-46c3-aef8-5a39552bc627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full symptom list and their embeddings\n",
    "with open(\"../model/model_all_symptoms.pkl\", \"rb\") as f:\n",
    "    symptom_list = pickle.load(f)\n",
    "\n",
    "with open(\"../model/model_symptom_embeddings.pkl\", \"rb\") as f:\n",
    "    symptom_embeddings = pickle.load(f)\n",
    "\n",
    "# Load sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c3026b8-672c-4c54-b0ce-d97d9902ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_symptom_match(user_input, top_k=10):\n",
    "    tokens = clean_input(user_input)\n",
    "    ngram_phrases = extract_ngrams(tokens)\n",
    "\n",
    "    # Step 1: Semantic match\n",
    "    input_vec = model.encode(\" \".join(tokens), convert_to_tensor=True).cpu()\n",
    "    semantic_scores = [\n",
    "        (sym, float(util.cos_sim(input_vec, emb)))\n",
    "        for sym, emb in symptom_embeddings.items()\n",
    "    ]\n",
    "    top_matches = sorted(semantic_scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Step 2: Exact match from n-grams\n",
    "    matched_syms = [sym for sym, _ in top_matches]\n",
    "    for sym in symptom_list:\n",
    "        if sym in ngram_phrases and sym not in matched_syms:\n",
    "            top_matches.append((sym, 0.95))  # Add fallback with high score\n",
    "\n",
    "    return sorted(top_matches, key=lambda x: x[1], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa2d50b9-fee4-424f-a008-146ef320afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ cough (0.9500)\n",
      "→ sharp chest pain (0.6292)\n",
      "→ burning chest pain (0.6018)\n",
      "→ nausea (0.5915)\n",
      "→ congestion in chest (0.5680)\n",
      "→ vomiting (0.5056)\n",
      "→ feeling ill (0.4995)\n",
      "→ shoulder cramps or spasms (0.4873)\n",
      "→ sore throat (0.4836)\n",
      "→ throat redness (0.4811)\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I feel feverish, have chest pain and have cough and even feel like nausea or vomiting\"\n",
    "\n",
    "results = hybrid_symptom_match(user_input)\n",
    "\n",
    "for sym, score in results:\n",
    "    print(f\"→ {sym} ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef98b4ff-1e86-42b5-a55f-db7319055b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")\n",
    "\n",
    "# Get list of unique symptoms\n",
    "symptom_list = df.columns[1:].tolist()\n",
    "\n",
    "# Load sentence transformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Precompute symptom embeddings\n",
    "symptom_embeddings = {sym: model.encode(sym, convert_to_tensor=True) for sym in symptom_list}\n",
    "\n",
    "# Clean and tokenize\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Hybrid matcher with n-gram and semantic similarity\n",
    "def extract_symptoms_semantic_phrases(user_input, top_k=10):\n",
    "    tokens = clean_and_tokenize(user_input)\n",
    "    print(tokens)\n",
    "    phrases = []\n",
    "    for n in range(1, 4):\n",
    "        phrases += [\" \".join(gram) for gram in ngrams(tokens, n)]\n",
    "    \n",
    "    seen = set()\n",
    "    scored_matches = []\n",
    "\n",
    "    for phrase in phrases:\n",
    "        if phrase in seen:\n",
    "            continue\n",
    "        seen.add(phrase)\n",
    "\n",
    "        input_vec = model.encode(phrase, convert_to_tensor=True)\n",
    "        scores = [(sym, float(util.cos_sim(input_vec, emb))) for sym, emb in symptom_embeddings.items()]\n",
    "        top_match = max(scores, key=lambda x: x[1])\n",
    "        if top_match[1] > 0.6:\n",
    "            scored_matches.append(top_match)\n",
    "\n",
    "    scored_matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scored_matches[:top_k]\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc57449e-c13b-4373-9dce-64783450bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feel', 'feverish', 'chest', 'pain', 'cough', 'even', 'feel', 'like', 'nausea', 'vomiting', 'even', 'shorten', 'breathing']\n",
      "vomiting → 1.0000\n",
      "cough → 1.0000\n",
      "nausea → 1.0000\n",
      "sharp chest pain → 0.8958\n",
      "nausea → 0.8743\n",
      "fever → 0.8605\n",
      "nausea → 0.8432\n",
      "nausea → 0.8271\n",
      "nausea → 0.8216\n",
      "vomiting → 0.8212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_input = \"I feel feverish, have chest pain and have cough and even feel like nausea or vomiting and even shorten breathing\"\n",
    "results = extract_symptoms_semantic_phrases(test_input)\n",
    "for symptom, score in results:\n",
    "    print(f\"{symptom} → {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bde3e91b-6ef2-4b89-99bd-c6529ec621b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jeetshah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "df = pd.read_csv(\"../data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")\n",
    "symptom_list = df.columns[1:].tolist()\n",
    "\n",
    "# Step 2: Load transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 3: Precompute symptom embeddings\n",
    "symptom_embeddings = {sym: model.encode(sym, convert_to_tensor=True) for sym in symptom_list}\n",
    "\n",
    "# Step 4: Text cleaner\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Step 5: Matching logic with deduplication\n",
    "def extract_symptoms_semantic_phrases(text, top_k=5):\n",
    "    tokens = clean_and_tokenize(text)\n",
    "    \n",
    "    phrases = []\n",
    "    for n in range(1, 4):\n",
    "        phrases += [\" \".join(gram) for gram in ngrams(tokens, n)]\n",
    "\n",
    "    seen = set()\n",
    "    matches = []\n",
    "\n",
    "    for phrase in phrases:\n",
    "        input_vec = model.encode(phrase, convert_to_tensor=True)\n",
    "        scored = [(sym, float(util.cos_sim(input_vec, emb))) for sym, emb in symptom_embeddings.items()]\n",
    "        best_symptom, best_score = max(scored, key=lambda x: x[1])\n",
    "\n",
    "        if best_score > 0.6 and best_symptom not in seen:\n",
    "            seen.add(best_symptom)\n",
    "            matches.append((best_symptom, best_score))\n",
    "\n",
    "    matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    return matches[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9306ca8-5507-41ac-a442-80baf7caa0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ fatigue (0.7206)\n",
      "→ insomnia (0.6901)\n",
      "→ sleepiness (0.6760)\n",
      "→ feeling hot (0.6316)\n"
     ]
    }
   ],
   "source": [
    "test_input = \"I feel tired and unable to sleep\"\n",
    "results = extract_symptoms_semantic_phrases(test_input, top_k=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8367a752-7c2a-412d-9f61-f922c3bd4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Time taken: 2.0046 seconds\n",
      "\n",
      "→ fatigue (0.7206)\n",
      "→ insomnia (0.6901)\n",
      "→ sleepiness (0.6760)\n",
      "→ feeling hot (0.6316)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "test_input = \"I feel tired and unable to sleep\"\n",
    "\n",
    "start = time.time()\n",
    "results = extract_symptoms_semantic_phrases(test_input, top_k=10)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\n✅ Time taken: {end - start:.4f} seconds\\n\")\n",
    "for symptom, score in results:\n",
    "    print(f\"→ {symptom} ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62269d2b-fc51-410f-822a-9d8bcf77d867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
